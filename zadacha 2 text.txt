Уязвимости моделей машинного обучения и как их минимизировать:

Внедрение – атаки, где данные специально подстраиваются для обмана модели. Защита: добавлять в обучение «шумные» примеры, чтобы модель научилась справляться с такими изменениями.

Отравление данных – подмена данных в обучающем наборе для снижения точности. Защита: фильтровать данные и использовать надежные источники.

Утечка данных – попытка извлечь информацию о данных, на которых модель обучалась. Защита: применять дифференциальную приватность (добавление шума) и регуляризацию.

Кража модели – попытки копировать модель через её ответы. Защита: ограничивать доступ к API и внедрять метки (watermarking) в модель.

Побочные каналы – уязвимости из-за аппаратных характеристик (время, энергия). Защита: контролировать доступ к устройству и усложнять анализ модели.

Эти меры повышают устойчивость модели к атакам и защита усиливается, если подходить комплексно.